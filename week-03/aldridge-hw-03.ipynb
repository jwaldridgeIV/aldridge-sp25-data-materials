{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ Before you start ⚠️\n",
    "\n",
    "_Duplicate this Jupyter Notebook in your `week-03` folder (right-click -> Duplicate) and then add your last name to the beginning of it (ie. `hw-03-blevins.ipynb` - otherwise you risk having all your work overwritten when you try to sync your GitHub repository with your instructor's repository._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ _No, seriously: check the name of this file. Is it the copy you made? (ie. `hw-03-blevins.ipynb`). If so, you can proceed_ ⚠️\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "Student Name: *Jessie Aldridge*  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're going to analyze several historical documents in this homework. In keeping with the theme of our first unit for the semester, **Slavery and Data**, I've chosen two 19th-century narratives written by formerly enslaved people: [Sojourner Truth](https://archive.org/details/narrativeofsojou1850gilb) and [Henry \"Box\" Brown](https://archive.org/details/narrativeofhenry00brow).\n",
    "\n",
    "You should have the following files:\n",
    "\n",
    "- `hw-03-yourlastname.ipynb` (your working version Jupyter Notebook)\n",
    "- `truth.txt` (Sojourner Truth's narrative)\n",
    "- `brown.txt` (Henry Brown's narrative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `open()` and `read()` functions to get the content of each of these files into Python, assigning them the corresponding variable names of `truth_fulltext` and `brown_fulltext`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('truth.txt', encoding='utf-8')\n",
    "truth_fulltext = open('truth.txt', mode='r', encoding='utf-8').read()\n",
    "\n",
    "open('brown.txt', encoding='utf-8')\n",
    "brown_fulltext = open('brown.txt', mode='r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two code cells, write print() statements that:\n",
    "\n",
    "- Print the **first 500 characters** of Truth's narrative.\n",
    "- Print characters **5000 to 6000** of Brown's narrative.\n",
    "\n",
    "Hint: use the index and slice approaches for strings: <https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/06-String-Methods.html>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NARRATIVE OF SOJOURNER TRUTH\\n\\n\\n\\n\\nHER BIRTH AND PARENTAGE.\\n\\n\\nTHE subject of this biography, SOJOURNER TRUTH, as she now calls\\nherself-but whose name, originally, was Isabella-was born, as near as\\nshe can now calculate, between the years 1797 and 1800.  She was the\\ndaughter of James and Betsey, slaves of one Colonel Ardinburgh, Hurley,\\nUlster County, New York.\\n\\nColonel  Ardinburgh belonged to that class of people called Low Dutch.\\n\\n\\nOf her first master, she can give no account, as she must have b'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_fulltext[0:499]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' of pity, indignation and\\nhorror.\\n\\nI first drew the breath of life in Louisa County, Va., forty-five miles\\nfrom the city of Richmond, in the year 1816. I was born a slave. Not\\nbecause at the moment of my birth an angel stood by, and declared that\\nsuch was the will of God concerning me; although in a country whose most\\nhonored writings declare that all men have a right to liberty, given\\nthem by their Creator, it seems strange that I, or any of my brethren,\\ncould have been born without this inalienable right, unless God had thus\\nsignified his departure from his usual rule, as described by our\\nfathers. Not, I say, on account of God’s willing it to be so, was I born\\na slave, but for the reason that nearly all the people of this country\\nare united in legislating against heaven, and have contrived to vote\\ndown our heavenly father’s rules, and to substitute for them, that cruel\\nlaw which binds the chains of slavery upon one sixth part of the\\ninhabitants of this land. I was born a slave! and w'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_fulltext[4999:5999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell complete the following:\n",
    "\n",
    "- Look at the printed out \"slice\" of Brown's narrative. Make a new variable and assign it a value of **Brown's birth year.**\n",
    "- Make a new variable and assign it a value of: **how old Henry Brown would have been in the year 1860.**\n",
    "- Write a **print statement** using your new variable that says how old Henry Brown would have been in 1860.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henry Brown would have been around the age of 44 in the year 1860.\n"
     ]
    }
   ],
   "source": [
    "brown_birthyr = 1816\n",
    "brown_age1860 = 1860 - brown_birthyr\n",
    "print(f\"Henry Brown would have been around the age of {brown_age1860} in the year 1860.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to compare how long each narrative is measured by the number of lines in each text. First, use the `split()` function for each narrative to break it apart by each new line. The new line character is `\\n`. Make two new variables storing a list of the broken apart text: `truth_lines` and `brown_lines`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_lines = truth_fulltext.split(\"\\n\")\n",
    "brown_lines = brown_fulltext.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which narrative has more lines? You can calculate how many lines are in each narrative through the `len()` function which will calculate the **length** of each list of lines you made in the previous section.\n",
    "\n",
    "- Write two print() statements to show **how many lines are in each narrative**.\n",
    "- Add a third print() statement that calculates **the difference between these two narratives measured by their number of lines**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in lines between these two works is 1404.\n"
     ]
    }
   ],
   "source": [
    "truth_lines_len = len(truth_lines)\n",
    "brown_lines_len = len(brown_lines)\n",
    "print(f\"The difference in lines between these two works is {truth_lines_len - brown_lines_len}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the `len()` and `comparison` functions with an `if statement` to print either `Sojourner Truth's narrative has more lines` or `Henry Brown's narrative has more lines` based on which has more lines.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sojourner Truth's work has more lines.\n"
     ]
    }
   ],
   "source": [
    "if truth_lines_len > brown_lines_len:\n",
    "    print(\"Sojourner Truth's work has more lines.\")\n",
    "elif brown_lines_len > truth_lines_len:\n",
    "    print(\"Henry Brown's work has more lines.\")\n",
    "else:\n",
    "    print(\"These two works have the same amount of lines! Incredible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Word Frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the code below from Melanie Walsh's \"Anatomy of a Python Script\" that she used to calculate the most frequently occurring words in a novel \"The Yellow Wallpapper.\" You are going to use this code as a starting point but change it to apply this same approach to the two texts we've been working with. Your goal: **compare the most frequently occuring words in both Truth's narrative and Brown's narrative.**\n",
    "\n",
    "Note: don't edit Walsh's code cell directly. Instead, copy and paste the code into **the two empty code cells below it** that you can then edit. If you accidentally overwrite it and need to find the original, you can [copy it from the original tutorial.](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/03-Anatomy-Python-Script.html)\n",
    "\n",
    "Adjustments you'll need to make to Walsh's code:\n",
    "\n",
    "- Open the right .txt file.\n",
    "- Find the most frequent **20 words** instead of 40 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Walsh's Code - copy this into a new code cell\n",
    "#import re\n",
    "#from collections import Counter\n",
    "#\n",
    "#def split_into_words(any_chunk_of_text):\n",
    "#    lowercase_text = any_chunk_of_text.lower()\n",
    "#    split_words = re.split(r\"\\W+\", lowercase_text)\n",
    "#    return split_words\n",
    "#\n",
    "#filepath_of_text = \"The-Yellow-Wallpaper_Charlotte-Perkins-Gilman.txt\"\n",
    "#number_of_desired_words = 40\n",
    "#\n",
    "#stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "# 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "# 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "#'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "# 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "# 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "# 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "# 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "# 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "# 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "# 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "# 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp', 'would', 'one']\n",
    "#\n",
    "#full_text = open(filepath_of_text, encoding=\"utf-8\").read()\n",
    "#\n",
    "#all_the_words = split_into_words(full_text)\n",
    "#meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "#meaningful_words_tally = Counter(meaningful_words)\n",
    "#most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)\n",
    "#\n",
    "#most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 86),\n",
       " ('slave', 85),\n",
       " ('slavery', 83),\n",
       " ('master', 81),\n",
       " ('upon', 80),\n",
       " ('slaves', 75),\n",
       " ('us', 62),\n",
       " ('god', 52),\n",
       " ('could', 52),\n",
       " ('people', 49),\n",
       " ('time', 48),\n",
       " ('south', 43),\n",
       " ('may', 43),\n",
       " ('wife', 38),\n",
       " ('men', 37),\n",
       " ('government', 33),\n",
       " ('yet', 31),\n",
       " ('made', 31),\n",
       " ('must', 31),\n",
       " ('never', 30)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(r\"\\W+\", lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "filepath_of_text = \"brown.txt\"\n",
    "number_of_desired_words = 20\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp', 'would', 'one']\n",
    "\n",
    "brown_full_text = open(filepath_of_text, encoding=\"utf-8\").read()\n",
    "\n",
    "brown_all_the_words = split_into_words(brown_full_text)\n",
    "brown_meaningful_words = [word for word in brown_all_the_words if word not in stopwords]\n",
    "brown_meaningful_words_tally = Counter(brown_meaningful_words)\n",
    "brown_most_frequent_meaningful_words = brown_meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "brown_most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('god', 128),\n",
       " ('isabella', 114),\n",
       " ('time', 114),\n",
       " ('could', 104),\n",
       " ('master', 78),\n",
       " ('go', 69),\n",
       " ('good', 67),\n",
       " ('said', 67),\n",
       " ('mr', 67),\n",
       " ('mother', 65),\n",
       " ('see', 64),\n",
       " ('much', 57),\n",
       " ('found', 53),\n",
       " ('like', 51),\n",
       " ('never', 50),\n",
       " ('well', 50),\n",
       " ('place', 50),\n",
       " ('son', 49),\n",
       " ('little', 49),\n",
       " ('new', 48)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(r\"\\W+\", lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "truth_filepath_of_text = \"truth.txt\"\n",
    "number_of_desired_words = 20\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp', 'would', 'one']\n",
    "\n",
    "truth_full_text = open(truth_filepath_of_text, encoding=\"utf-8\").read()\n",
    "\n",
    "truth_all_the_words = split_into_words(truth_full_text)\n",
    "truth_meaningful_words = [word for word in truth_all_the_words if word not in stopwords]\n",
    "truth_meaningful_words_tally = Counter(truth_meaningful_words)\n",
    "truth_most_frequent_meaningful_words = truth_meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "truth_most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the 20 most frequent words for each narrative. In the Markdown cell below, write down **three observations you have about this data.** These might be similarities between the two narratives, differences between the two, or any other patterns or questions you notice based on their word frequency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation 1:*\n",
    "\n",
    "Although they both have a focus on religiosity with the mentions of God throughout, Truth's document has \"God\" as the most referenced word in the whole work.\n",
    "\n",
    "*Observation 2:*\n",
    "\n",
    "Brown's work is heavily laden with references to the institution of slavery, with many of the top words being directly or indirectly related to that.\n",
    "\n",
    "*Observation 3:*\n",
    "\n",
    "Sojourner Truth's breakdown of the document shows family played a large role in her life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text files you've used in this homework were not the original text files of these narratives. Instead, they've been cleaned by your instructor to make them shorter and easier to analyze. Your goal is to use Python to download the original `.txt` files from the website Project Gutenberg. Adapt the code from [these examples](https://python.omics.wiki/www/download-webpage) and use Python's `urllib` package to download the narratives and save them as local files named `truth-original.txt` and `brown-original.txt`.\n",
    "\n",
    "Here are the URL's for the two original text files on Project Gutenberg:\n",
    "\n",
    "- Truth's narrative: <https://www.gutenberg.org/cache/epub/1674/pg1674.txt>\n",
    "- Brown's narrative: <https://www.gutenberg.org/cache/epub/64992/pg64992.txt>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('brown-original.txt', <http.client.HTTPMessage at 0x107b1a4e0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://www.gutenberg.org/cache/epub/1674/pg1674.txt\",\"truth-original.txt\")\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://www.gutenberg.org/cache/epub/64992/pg64992.txt\",\"brown-original.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code for the following:\n",
    "\n",
    "- Open and read each of the new text files you just downloaded.\n",
    "- Print out the **number of lines** in each of the original (newly downloaded) text files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in lines between these two original works is 1273.\n"
     ]
    }
   ],
   "source": [
    "open('truth-original.txt', encoding='utf-8')\n",
    "truth_original_fulltext = open('truth-original.txt', mode='r', encoding='utf-8').read()\n",
    "\n",
    "open('brown-original.txt', encoding='utf-8')\n",
    "brown_original_fulltext = open('brown-original.txt', mode='r', encoding='utf-8').read()\n",
    "\n",
    "truth_original_lines = truth_original_fulltext.split(\"\\n\")\n",
    "brown_original_lines = brown_original_fulltext.split(\"\\n\")\n",
    "\n",
    "truth_original_lines_len = len(truth_original_lines)\n",
    "brown_original_lines_len = len(brown_original_lines)\n",
    "print(f\"The difference in lines between these two original works is {truth_original_lines_len - brown_original_lines_len}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the length of the original text files you just downloaded to the cleaned text files you used for the rest of the homework, measured by the number of lines.\n",
    "\n",
    "Write two print() statements that calculate **how many lines were removed by the instructor for each narrative.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor Blevins removed 460 lines from Truth's document, as well as 591 from Brown's document! How could he...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Professor Blevins removed {truth_original_lines_len - truth_lines_len} lines from Truth's document, as well as {brown_original_lines_len - brown_lines_len} from Brown's document! How could he...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What sort of text did the instructor remove? Write Python code that allows you to compare the two versions Sojourner Truth's narrative. Then write a few sentences in the empty Markdown cell below explaining what you found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the most frequent words in the original document by Sojourner Truth:\n",
      "[('god', 128), ('isabella', 118), ('time', 114), ('could', 105), ('gutenberg', 97), ('project', 88), ('master', 80), ('work', 78), ('go', 69), ('good', 67), ('see', 67), ('said', 67), ('mr', 67), ('mother', 66), ('much', 58), ('found', 55), ('new', 53), ('like', 51), ('place', 51), ('son', 50)]\n",
      "These are the most frequent words in the edited down version by Professor Blevins:\n",
      "[('god', 128), ('isabella', 114), ('time', 114), ('could', 104), ('master', 78), ('go', 69), ('good', 67), ('said', 67), ('mr', 67), ('mother', 65), ('see', 64), ('much', 57), ('found', 53), ('like', 51), ('never', 50), ('well', 50), ('place', 50), ('son', 49), ('little', 49), ('new', 48)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def split_into_words(any_chunk_of_text):\n",
    "    lowercase_text = any_chunk_of_text.lower()\n",
    "    split_words = re.split(r\"\\W+\", lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "truth_original_filepath_of_text = \"truth-original.txt\"\n",
    "number_of_desired_words = 20\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp', 'would', 'one']\n",
    "\n",
    "truth_original_full_text = open(truth_original_filepath_of_text, encoding=\"utf-8\").read()\n",
    "\n",
    "truth_original_all_the_words = split_into_words(truth_original_full_text)\n",
    "truth_original_meaningful_words = [word for word in truth_original_all_the_words if word not in stopwords]\n",
    "truth_original_meaningful_words_tally = Counter(truth_original_meaningful_words)\n",
    "truth_original_most_frequent_meaningful_words = truth_original_meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "print(\"These are the most frequent words in the original document by Sojourner Truth:\")\n",
    "\n",
    "print(f\"{truth_original_most_frequent_meaningful_words}\")\n",
    "\n",
    "print(\"These are the most frequent words in the edited down version by Professor Blevins:\")\n",
    "\n",
    "print(f\"{truth_most_frequent_meaningful_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly it seems like the professor cut out some dialogue and other small random stuff that maybe did not add to the story. The amount of \"God\" appearing not changing makes me think that the document could be in different parts for her different parts of her life. Also the professor has cut out all of the text relating to the host of the text, Project Gutenberg, so the text is solely what was written by Truth so we could analyze it better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
